import pandas as pd
import numpy as np


data = pd.DataFrame ({
    'age':[25, np.nan, 40, 45, np.nan],
    'salary':[50000, 60000, np.nan, 65000, 70000],
    'city':['New York','Los Angeles','New York','San Francisco', np.nan ],
    'target':[1,0,1,0,1]
})


print("\nOriginal data")
print(data)
print("\nMissing values")
print(data.isnull().sum())
print("\nPercentage of missing values")
print(data.isnull().mean()*100)


#handling missing values`
data2 = data.dropna()
print("after removing rows:")
print(data2)


#data2 = data.dropna(axis=1)
#print('after removing columns:')
#print(data2)


from sklearn.impute import SimpleImputer


#numerical features
num_features = ['age', 'salary' ] 
imputer_num = SimpleImputer(strategy='mean')
data[num_features] = imputer_num.fit_transform(data[num_features])


#categorical features 
cat_features = [ 'city' ]
imputer_cat = SimpleImputer(strategy='most_frequent')
data[cat_features] = imputer_cat.fit_transform(data[cat_features])


from sklearn.preprocessing import StandardScaler, LabelEncoder


#encoding categorical features 
label_encoders = {}
for col in cat_features:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le


scaler = StandardScaler()
num_features = ['age', 'salary']
data[num_features] = scaler.fit_transform(data[num_features])
data.to_csv('cleaned_dataset.csv', index=False)


data1 = pd.read_csv('cleaned_dataset.csv')
print('df to csv')
print(data1)



